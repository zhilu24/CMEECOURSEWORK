{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82315ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2f912f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_sequences(faa_path, top_n=10, min_len=100, max_len=2000):\n",
    "    records = list(SeqIO.parse(faa_path, \"fasta\"))\n",
    "    \n",
    "    # Filter out sequences that are too short or too long\n",
    "    filtered = [r for r in records if min_len <= len(r.seq) <= max_len]\n",
    "    \n",
    "    # Skip the file if fewer than top_n valid sequences are available\n",
    "    if len(filtered) < top_n:\n",
    "        return None\n",
    "\n",
    "    # Select the top_n longest sequences\n",
    "    sorted_records = sorted(filtered, key=lambda r: len(r.seq), reverse=True)\n",
    "    return sorted_records[:top_n]\n",
    "\n",
    "def process_all_faa(input_dir, output_dir, top_n=10, min_len=100, max_len=2000):\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    faa_files = list(input_dir.glob(\"*.faa\"))\n",
    "    print(f\"Found {len(faa_files)} .faa files\")\n",
    "\n",
    "    for faa_file in faa_files:\n",
    "        top_seqs = get_top_sequences(faa_file, top_n=top_n, min_len=min_len, max_len=max_len)\n",
    "        if top_seqs is None:\n",
    "            print(f\"Skipped {faa_file.name}: fewer than {top_n} valid sequences\")\n",
    "            continue\n",
    "\n",
    "        output_file = output_dir / faa_file.name\n",
    "        SeqIO.write(top_seqs, output_file, \"fasta\")\n",
    "        print(f\"Saved {len(top_seqs)} sequences from {faa_file.name}\")\n",
    "\n",
    "# Example usage\n",
    "process_all_faa(\"../data/filtered_output\", \"../data/test_protein_sequences/selected_seqs_final\", top_n=10, min_len=100, max_len=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d94488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path settings\n",
    "label_file = \"../data/temperature_data.tsv\"  # Contains taxid and temperature labels\n",
    "faa_dir = Path(\"../data/test_protein_sequences/selected_seqs_final\")  # Directory containing .faa files\n",
    "\n",
    "# Read label file\n",
    "df = pd.read_csv(label_file, sep=\"\\t\")\n",
    "df[\"taxid\"] = df[\"taxid\"].astype(str).str.strip()\n",
    "\n",
    "# Build a dict mapping taxid -> temperature\n",
    "temperature_dict = dict(zip(df[\"taxid\"], df[\"temperature\"]))\n",
    "\n",
    "strain_level_data = {}\n",
    "\n",
    "# Iterate over all .faa files\n",
    "for faa_file in faa_dir.glob(\"*.faa\"):\n",
    "    filename = faa_file.name\n",
    "    taxid = filename.split(\"_\")[0].strip()  # Extract taxid from the filename prefix\n",
    "\n",
    "    if taxid not in temperature_dict:\n",
    "        print(f\"⚠️ taxid {taxid} not found in labels, skipping {filename}\")\n",
    "        continue\n",
    "\n",
    "    sequences = []\n",
    "    for record in SeqIO.parse(faa_file, \"fasta\"):\n",
    "        seq = str(record.seq).strip()\n",
    "        if seq:\n",
    "            sequences.append(seq)\n",
    "\n",
    "    if not sequences:\n",
    "        print(f\"⚠️ No valid sequences in {filename}, skipping\")\n",
    "        continue\n",
    "\n",
    "    strain_level_data[taxid] = {\n",
    "        \"sequences\": sequences,\n",
    "        \"label\": float(temperature_dict[taxid])\n",
    "    }\n",
    "\n",
    "# Save as JSON\n",
    "with open(\"strain_level_data.json\", \"w\") as f:\n",
    "    json.dump(strain_level_data, f, indent=2)\n",
    "\n",
    "print(f\"✅ Finished building dataset with {len(strain_level_data)} strains.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41482e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load strain_level_data.json\n",
    "with open(\"strain_level_data.json\", \"r\") as f:\n",
    "    strain_data_final = json.load(f)\n",
    "\n",
    "# Flatten into a list while keeping strain_id\n",
    "train_data_final = []\n",
    "\n",
    "for strain_id, entry in strain_data_final.items():\n",
    "    label = entry[\"label\"]\n",
    "    for seq in entry[\"sequences\"]:\n",
    "        train_data_final.append({\n",
    "            \"sequence\": seq,\n",
    "            \"label\": label,\n",
    "            \"strain_id\": strain_id  \n",
    "        })\n",
    "\n",
    "# Save as JSON usable by Trainer\n",
    "with open(\"train_data_final.json\", \"w\") as f:\n",
    "    json.dump(train_data_final, f, indent=2)\n",
    "\n",
    "print(f\" Finished building — total {len(train_data_final)} training samples\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
